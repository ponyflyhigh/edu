# asr_stream.py
# å®æ—¶è¯­éŸ³è¯†åˆ«æ¨¡å—ï¼Œå¢å¼ºé”™è¯¯å¤„ç†å’Œèµ„æºç®¡ç†

import pyaudio
import webrtcvad
import socket
from dashscope.audio.asr import Recognition, RecognitionCallback, RecognitionResult
from dashscope.common.error import InvalidParameter  # å¯¼å…¥é”™è¯¯ç±»å‹

# é…ç½®å‚æ•°
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 320
VAD_AGGRESSIVENESS = 2
SILENCE_THRESHOLD = 15
PRE_ROLL = 10
HOST = '127.0.0.1'
PORT = 5000

class ASRCallback(RecognitionCallback):
    """ASRå›è°ƒå‡½æ•°ï¼Œå¤„ç†å®Œæ•´è¯†åˆ«æ–‡æœ¬"""
    def __init__(self):
        self.text = ""
    
    def on_event(self, result: RecognitionResult) -> None:
        sentence = result.get_sentence()
        if isinstance(sentence, str):
            self.text = sentence
            print(f"ğŸ™ï¸ è¯†åˆ«ç»“æœ: {self.text}")
        elif isinstance(sentence, dict) and 'text' in sentence:
            self.text = sentence['text']
            print(f"ğŸ™ï¸ è§£ææ–‡æœ¬: {self.text}")


class ASRStream:
    """è¯­éŸ³è¯†åˆ«æµç®¡ç†ï¼Œå¢å¼ºé”™è¯¯å¤„ç†"""
    def __init__(self):
        self.p = pyaudio.PyAudio()
        self.vad = webrtcvad.Vad(VAD_AGGRESSIVENESS)
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.asr = None
        self.stream = None
        self.connected = False
    
    def connect(self):
        """è¿æ¥åˆ°å¤§æ¨¡å‹æœåŠ¡"""
        try:
            self.socket.connect((HOST, PORT))
            self.connected = True
            print(f"âœ… è¿æ¥åˆ°æ–‡æœ¬æœåŠ¡ {HOST}:{PORT}")
            return True
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            self.connected = False
            return False
    
    def start(self):
        """å¯åŠ¨è¯†åˆ«æµï¼Œå¢å¼ºé”™è¯¯å¤„ç†"""
        if not self.connect():
            return
        
        print("\nğŸ‘‚ å¼€å§‹ç›‘å¬éº¦å…‹é£...")
        
        while True:
            try:
                self._start_new_recognition()
            except InvalidParameter as e:
                if "Speech recognition has stopped." in str(e):
                    print(f"â„¹ï¸ è¯†åˆ«æœåŠ¡å·²åœæ­¢ï¼Œé‡æ–°å¯åŠ¨: {e}")
                else:
                    print(f"âŒ è¯†åˆ«é”™è¯¯: {e}")
            except Exception as e:
                print(f"âŒ å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
            finally:
                self._cleanup_current_session()
                print("\n--- å‡†å¤‡ä¸‹ä¸€æ¬¡è¯†åˆ« ---")
    
    def _start_new_recognition(self):
        """å¯åŠ¨æ–°çš„è¯†åˆ«ä¼šè¯ï¼Œåˆ†ç¦»æ ¸å¿ƒé€»è¾‘"""
        self.stream = self.p.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK
        )
        callback = ASRCallback()
        self.asr = Recognition(
            model='paraformer-realtime-v2',
            format='pcm',
            sample_rate=RATE,
            callback=callback
        )
        self.asr.start()
        
        speech_detected = False
        silence_frames = 0
        
        try:
            while True:
                data = self.stream.read(CHUNK, exception_on_overflow=False)
                is_speech = self.vad.is_speech(data, RATE)
                
                if not speech_detected:
                    if is_speech:
                        speech_detected = True
                        silence_frames = 0
                        print("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³")
                        self.asr.send_audio_frame(data)
                else:
                    self.asr.send_audio_frame(data)
                    
                    if not is_speech:
                        silence_frames += 1
                        if silence_frames > SILENCE_THRESHOLD:
                            print("ğŸ”‡ è¯­éŸ³ç»“æŸ")
                            self._send_text(callback.text)
                            callback.text = ""
                            break
        finally:
            # ç¡®ä¿åœ¨å¼‚å¸¸æ—¶ä¹Ÿèƒ½æ­£ç¡®æ¸…ç†
            if self.asr:
                self.asr.stop()
    
    def _send_text(self, text):
        """å‘é€æ–‡æœ¬åˆ°å¤§æ¨¡å‹ï¼Œå¢å¼ºé”™è¯¯å¤„ç†"""
        if not text:
            print("âš ï¸ æ— æœ‰æ•ˆæ–‡æœ¬")
            return
        
        print(f"ğŸ“¤ å‘é€æ–‡æœ¬: {text}")
        try:
            self.socket.sendall(text.encode('utf-8') + b'\n')
        except Exception as e:
            print(f"âŒ å‘é€å¤±è´¥: {e}")
            self.connect()
    
    def _cleanup_current_session(self):
        """æ¸…ç†å½“å‰ä¼šè¯èµ„æºï¼Œé¿å…å¤šæ¬¡åœæ­¢é”™è¯¯"""
        if self.asr:
            try:
                self.asr.stop()
            except InvalidParameter:
                pass  # å¿½ç•¥å·²åœæ­¢çš„é”™è¯¯
            self.asr = None
        
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
    
    def cleanup(self):
        """å…¨å±€èµ„æºæ¸…ç†"""
        self._cleanup_current_session()
        if self.connected:
            self.socket.close()
        self.p.terminate()
        print("ğŸ‘‹ è¯†åˆ«æ¨¡å—å·²é€€å‡º")

if __name__ == "__main__":
    asr = ASRStream()
    try:
        asr.start()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
    finally:
        asr.cleanup()